rand_x <- sample(1:50, size = 1)
coords <- data.frame(rand_x, rand_y)
all_coords[i,1] <- rand_x
all_coords[i,2] <- rand_y
}
if(dim(all_coords %>% distinct())[1] != 20) {stop()}
ordered_by_y <- all_coords %>%
arrange(X2)
pairs <- c(rep("a", times = 10), rep("b", times = 10))
ordered_by_teams <- cbind(ordered_by_y, pairs)
ordered_final <- ordered_by_teams %>%
group_by(pairs) %>%
arrange(X1, .by_group = TRUE)
ordered_final
write.csv(ordered_final, "C:\\Users\\ethan\\Documents\\MBQ\\coords07.csv")
rm(.Random.seed, envir=globalenv())
for(i in 1:num_bommies){
rand_y <- sample(-10:10, size = 1)
rand_x <- sample(1:50, size = 1)
coords <- data.frame(rand_x, rand_y)
all_coords[i,1] <- rand_x
all_coords[i,2] <- rand_y
}
library(tidyverse)
num_bommies <- 20
all_coords <- data.frame(matrix(NA, nrow = num_bommies, ncol = 2))
rm(.Random.seed, envir=globalenv())
rm(.Random.seed, envir=globalenv())
for(i in 1:num_bommies){
rand_y <- sample(-10:10, size = 1)
rand_x <- sample(1:50, size = 1)
coords <- data.frame(rand_x, rand_y)
all_coords[i,1] <- rand_x
all_coords[i,2] <- rand_y
}
all_coords
rm(.Random.seed, envir=globalenv())
rm(.Random.seed, envir=globalenv())
for(i in 1:num_bommies){
rand_y <- sample(-10:10, size = 1)
rand_x <- sample(1:50, size = 1)
coords <- data.frame(rand_x, rand_y)
all_coords[i,1] <- rand_x
all_coords[i,2] <- rand_y
}
all_coords
library(tidyverse)
num_bommies <- 20
all_coords <- data.frame(matrix(NA, nrow = num_bommies, ncol = 2))
rm(.Random.seed, envir=globalenv())
for(i in 1:num_bommies){
rand_y <- sample(-5:5, size = 1)
rand_x <- sample(1:100, size = 1)
coords <- data.frame(rand_x, rand_y)
all_coords[i,1] <- rand_x
all_coords[i,2] <- rand_y
}
if(dim(all_coords %>% distinct())[1] != 20) {stop()}
ordered_by_y <- all_coords %>%
arrange(X2)
pairs <- c(rep("a", times = 10), rep("b", times = 10))
ordered_by_teams <- cbind(ordered_by_y, pairs)
ordered_final <- ordered_by_teams %>%
group_by(pairs) %>%
arrange(X1, .by_group = TRUE)
ordered_final
write.csv(ordered_final, "C:\\Users\\ethan\\Documents\\MBQ\\coords08.csv")
?Rm
?rm
rm(.Random.seed, envir=globalenv())
for(i in 1:num_bommies){
rand_y <- sample(-10:10, size = 1)
rand_x <- sample(1:50, size = 1)
coords <- data.frame(rand_x, rand_y)
all_coords[i,1] <- rand_x
all_coords[i,2] <- rand_y
}
if(dim(all_coords %>% distinct())[1] != 20) {stop()}
library(tidyverse)
num_bommies <- 20
all_coords <- data.frame(matrix(NA, nrow = num_bommies, ncol = 2))
rm(.Random.seed, envir=globalenv())
for(i in 1:num_bommies){
rand_y <- sample(-10:10, size = 1)
rand_x <- sample(1:50, size = 1)
coords <- data.frame(rand_x, rand_y)
all_coords[i,1] <- rand_x
all_coords[i,2] <- rand_y
}
if(dim(all_coords %>% distinct())[1] != 20) {stop()}
ordered_by_y <- all_coords %>%
arrange(X2)
pairs <- c(rep("a", times = 10), rep("b", times = 10))
ordered_by_teams <- cbind(ordered_by_y, pairs)
ordered_final <- ordered_by_teams %>%
group_by(pairs) %>%
arrange(X1, .by_group = TRUE)
ordered_final
write.csv(ordered_final, "C:\\Users\\ethan\\Documents\\MBQ\\coords09.csv")
library(tidyverse)
library(broom)
theme_set(theme_classic())
data("Marketing", package = "datarium")
install.packages("datarium")
data("Marketing", package = "datarium")
data("marketing", package = "datarium")
sample_n(marketing, 3)
model <- lm(sales ~youtube, data = marketing)
model
model.diag.metrics <- augment(model)
?augment
model.diag.metrics <- broom::augment(model)
head(model.diag.metrics)
head(model.diag.metrics)
head(model.diag.metrics)
ggplot(model.diag.metrics, aes(youtube, sales)) +
geom_point() +
stat_smooth(method = lm, se = FALSE) +
geom_segment(aes(xend = youtube, yend = .fitted), color = "red", size = 0.3)
model.diag.metrics$.fitted
par(mfrow = c(2,2))
plot(model)
# drop some columns (.se.fit, .sigma) for simplification
model.diag.metrics <- model.diag.metrics %>%
mutate(index = 1:nrow(model.diag.metrics)) %>%
select(index, everything(), -.se.fit, -.sigma)
# drop some columns (.se.fit, .sigma) for simplification
model.diag.metrics <- model.diag.metrics %>%
mutate(index = 1:nrow(model.diag.metrics)) %>%
select(index, everything(), -.sigma)
# Inspect the data
head(model.diag.metrics, 4)
library(lme4)
library(tidyverse)
raw.data.full <- read.csv("data/2024_boringData_masterSheet - complete_data(1).csv")
raw.data.full <- read.csv("data/2024_boringData_masterSheet - complete_data(1).csv")
wd
set.wd()
getwd()
setwd("C:\\Users\\ethan\\Documents\\R\\MBQ S24 Boring")
library(lme4)
library(tidyverse)
raw.data.full <- read.csv("data/2024_boringData_masterSheet - complete_data(1).csv")
raw.data.no.diameters <- raw.data0 %>% select(2:70)
raw.data <- raw.data.no.diameters %>% select(-(44:54))
z.score <- function(x) {
centered <- x - mean(x)
scaled <- centered/sd(centered)
return(scaled)
}
## Decided to use Poisson distribution for point counts, because densities were not normally distributed
z.data <- raw.data %>% mutate(live_coral_z = z.score(live_coral_total),
dead_coral_z = z.score(dead_coral_total),
turf_z = z.score(turf_total),
macroalgae_z = z.score(macroalgae_total),
rock_z = z.score(rock_total),
invertebrate_z = z.score(invertebrate_total),
number_total_points_z = z.score(number_total_points),
depth_to_benthos_z = z.score(depth_to_benthos),
percent_N_jan_z =z.score(percent_N_jan),
percent_N_may_z = z.score(percent_N_may),
percent_N_aug_z = z.score(percent_N_aug),
jan_d15_z = z.score(jan_d15),
may_d15_z = z.score(may_d15),
aug_d15_z = z.score(aug_d15),
NHW_speed_z = z.score(NHW_speed),
NLW_speed_z = z.score(NLW_speed),
ELW_speed_z = z.score(ELW_speed),
avg_speed_z = z.score(avg_speed),
NHW_speed_offshore_z = z.score(NHW_speed_offshore),
NLW_speed_offshore_z = z.score(NLW_speed_offshore),
ELW_speed_offshore_z = z.score(ELW_speed_offshore),
avg_speed_offshore_z = z.score(avg_speed_offshore),
distanceOutBay_z = z.score(distanceOutBay))
head(z.data)
mean(z.data$L_onLive)
mean(z.data$L_onDead)
mean(z.data$D_liveOnLive)
mean(z.data$D_liveOnDead)
##### L on live (z-score)
model_L_onLive_z <- glm(L_onLive ~
live_coral_z + dead_coral_z + turf_z +
macroalgae_z + rock_z + invertebrate_z + depth_to_benthos_z +
percent_N_jan_z + percent_N_may_z + percent_N_aug_z +
jan_d15_z + may_d15_z + aug_d15_z +
NHW_speed_z + NLW_speed_z + ELW_speed_z +
NHW_speed_offshore_z + NLW_speed_offshore_z + ELW_speed_offshore_z
#avg_speed_z + avg_speed_offshore_z +
#+distanceOutBay_z
,
family = poisson,
data = z.data)
step_L_onLive_z <- glm(formula = L_onLive ~ live_coral_z + dead_coral_z + turf_z +
rock_z + invertebrate_z + depth_to_benthos_z + percent_N_jan_z +
percent_N_may_z + percent_N_aug_z + jan_d15_z + may_d15_z +
aug_d15_z + NLW_speed_z, family = poisson, data = z.data)
summary(step_L_onLive_z)
##### Trying to figure out overdispersion in my Poisson models
overdisp_fun <- function(model) {
rdf <- df.residual(model)
rp <- residuals(model,type="pearson")
Pearson.chisq <- sum(rp^2)
prat <- Pearson.chisq/rdf
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}
step_L_onLive_z <- glm(formula = L_onLive ~ live_coral_z + dead_coral_z + turf_z +
rock_z + invertebrate_z + depth_to_benthos_z + percent_N_jan_z +
percent_N_may_z + percent_N_aug_z + jan_d15_z + may_d15_z +
aug_d15_z + NLW_speed_z, family = poisson, data = z.data)
summary(step_L_onLive_z)
overdisp_fun(step_L_onLive_z)
##testing something silly? un-scale everyhting
model_L_onLive <- glm(L_onLive ~
live_coral + dead_coral + turf +
macroalgae + rock + invertebrate + depth_to_benthos +
percent_N_jan + percent_N_may + percent_N_aug +
jan_d15 + may_d15 + aug_d15 +
NHW_speed + NLW_speed + ELW_speed +
NHW_speed_offshore + NLW_speed_offshore + ELW_speed_offshore,
family = poisson,
data = raw.data)
head(raw.data)
##testing something silly? un-scale everyhting
model_L_onLive <- glm(L_onLive ~
live_coral_total + dead_coral_total + turf_total +
macroalgae_total + rock_total + invertebrate_total + depth_to_benthos +
percent_N_jan + percent_N_may + percent_N_aug +
jan_d15 + may_d15 + aug_d15 +
NHW_speed + NLW_speed + ELW_speed +
NHW_speed_offshore + NLW_speed_offshore + ELW_speed_offshore,
family = poisson,
data = raw.data)
step(model_L_onLive)
summary(model_L_onLive)
step_L_onLive <- glm(formula = L_onLive ~ live_coral_total + dead_coral_total +
turf_total + rock_total + invertebrate_total + depth_to_benthos +
percent_N_jan + percent_N_may + percent_N_aug + jan_d15 +
may_d15 + aug_d15 + NLW_speed, family = poisson, data = raw.data)
summary(step_L_onLive)
overdisp_fun(step_L_onLive)
quasi_table <- function(model,ctab=coef(summary(model)),
phi=overdisp_fun(model)["ratio"]) {
qctab <- within(as.data.frame(ctab),
{   `Std. Error` <- `Std. Error`*sqrt(phi)
`z value` <- Estimate/`Std. Error`
`Pr(>|z|)` <- 2*pnorm(abs(`z value`), lower.tail=FALSE)
})
return(qctab)
}
printCoefmat(quasi_table(m1),digits=3)
printCoefmat(quasi_table(step_L_onLive_z),digits=3)
library(broom.mixed)
install.packages("broom.mixed")
library(broom.mixed)
tidy_quasi <- function(model, phi=overdisp_fun(model)["ratio"],
conf.level=0.95) {
tt <- (tidy(model, effects="fixed")
%>% mutate(std.error=std.error*sqrt(phi),
statistic=estimate/std.error,
p.value=2*pnorm(abs(statistic), lower.tail=FALSE))
)
return(tt)
}
tidy_quasi(step_L_onLive_z)
tidy_quasi(model_L_onLive_z)
tidy_quasi(step_L_onLive_z)
?glmer.nb
nb_L_onLive_z <- glmer.nb(L_onLive ~
live_coral_z + dead_coral_z + turf_z +
macroalgae_z + rock_z + invertebrate_z + depth_to_benthos_z +
percent_N_jan_z + percent_N_may_z + percent_N_aug_z +
jan_d15_z + may_d15_z + aug_d15_z +
NHW_speed_z + NLW_speed_z + ELW_speed_z +
NHW_speed_offshore_z + NLW_speed_offshore_z + ELW_speed_offshore_z, data = z.data)
##### L on dead (z-score)
model_L_onDead_z <- glm(L_onDead ~
live_coral_z + dead_coral_z + turf_z +
macroalgae_z + rock_z + invertebrate_z + depth_to_benthos_z +
percent_N_jan_z + percent_N_may_z + percent_N_aug_z +
jan_d15_z + may_d15_z + aug_d15_z +
NHW_speed_z + NLW_speed_z + ELW_speed_z,
family = poisson,
data = z.data)
step(model_L_onDead_z)
step_L_onDead_z <- glm(formula = L_onDead ~ live_coral_z + dead_coral_z + turf_z +
macroalgae_z + rock_z + invertebrate_z + depth_to_benthos_z +
percent_N_jan_z + percent_N_may_z + jan_d15_z + may_d15_z +
aug_d15_z + NHW_speed_z + NLW_speed_z, family = poisson,
data = z.data)
tidy_quasi(step_L_onDead_z)
tidy_quasi(step_L_onLive_z)
tidy_quasi(step_L_onDead_z)
summary(step_L_onDead_z)
overdisp_fun(step_L_onDead_z)
##### Live D on live (z-score)
model_D_liveOnLive_z <- glm(D_liveOnLive ~
live_coral_z + dead_coral_z + turf_z +
macroalgae_z + rock_z + invertebrate_z + depth_to_benthos_z +
percent_N_jan_z + percent_N_may_z + percent_N_aug_z +
jan_d15_z + may_d15_z + aug_d15_z +
NHW_speed_z + NLW_speed_z + ELW_speed_z,
family = poisson,
data = z.data)
step(model_D_liveOnLive_z)
step_D_liveOnLive_z <- glm(formula = D_liveOnLive ~ live_coral_z + invertebrate_z +
depth_to_benthos_z + percent_N_jan_z + percent_N_aug_z +
may_d15_z + aug_d15_z + NHW_speed_z + NLW_speed_z, family = poisson,
data = z.data)
summary(step_D_liveOnLive_z)
##### Live D on live (z-score)
model_D_liveOnLive_z <- glm(D_liveOnLive ~
live_coral_z + dead_coral_z + turf_z +
macroalgae_z + rock_z + invertebrate_z + depth_to_benthos_z +
percent_N_jan_z + percent_N_may_z + percent_N_aug_z +
jan_d15_z + may_d15_z + aug_d15_z +
NHW_speed_z + NLW_speed_z + ELW_speed_z,
family = poisson,
data = z.data)
summary(step_D_liveOnLive_z)
overdisp_fun(step_D_liveOnLive_z)
tidy_quasi(step_D_liveOnLive_z)
overdisp_fun(model_D_liveOnLive_z)
tidy_quasi(model_D_liveOnLive_z)
overdisp_fun(step_D_liveOnLive_z)
tidy_quasi(step_D_liveOnLive_z)
##### Live D on dead (z-score)
model_D_liveOnDead_z <- glm(D_liveOnDead ~
live_coral_z + dead_coral_z + turf_z +
macroalgae_z + rock_z + invertebrate_z + depth_to_benthos_z +
percent_N_jan_z + percent_N_may_z + percent_N_aug_z +
jan_d15_z + may_d15_z + aug_d15_z +
NHW_speed_z + NLW_speed_z + ELW_speed_z,
family = poisson,
data = z.data)
step(model_D_liveOnDead_z)
step_D_liveOnDead_z <- glm(formula = D_liveOnDead ~ live_coral_z + dead_coral_z + turf_z +
macroalgae_z + rock_z + invertebrate_z + depth_to_benthos_z +
percent_N_jan_z + percent_N_may_z + percent_N_aug_z + jan_d15_z +
may_d15_z + aug_d15_z + NHW_speed_z + NLW_speed_z, family = poisson,
data = z.data)
summary(step_D_liveOnDead_z)
overdisp_fun(step_D_liveOnDead_z)
quasi_table(step_D_liveOnDead_z)
##### L on live (z-score)
model_L_onLive_z <- glm(L_onLive ~
live_coral_z + dead_coral_z + turf_z +
macroalgae_z + rock_z + invertebrate_z + depth_to_benthos_z +
percent_N_jan_z + percent_N_may_z + percent_N_aug_z +
jan_d15_z + may_d15_z + aug_d15_z +
NHW_speed_z + NLW_speed_z + ELW_speed_z +
NHW_speed_offshore_z + NLW_speed_offshore_z + ELW_speed_offshore_z
#avg_speed_z + avg_speed_offshore_z +
#+distanceOutBay_z
,
family = quasipoisson,
data = z.data)
summary(model_L_onLive)
summary(model_L_onLive_z)
step(model_L_onLive_z)
quasi_L_onLive_z <- glm(L_onLive ~
live_coral_z + dead_coral_z + turf_z +
macroalgae_z + depth_to_benthos_z +
percent_N_jan_z + percent_N_may_z + percent_N_aug_z +
jan_d15_z + may_d15_z + aug_d15_z +
NHW_speed_z + NLW_speed_z + ELW_speed_z,
family = quasipoisson,
data = z.data)
summary(quasi_L_onLive_z)
quasi_L_onLive_z
install.packages("Hmisc")
library(Hmisc)
rcorr(as.matrix(z.data))
cor(z.data))
cor(z.data)
head(z.data)
z.data[,c(32:43, 59:81)]
rcorr
rcorr(as.matrix(z.data[,c(32:43, 59:81)]))
rcorr(as.matrix(z.data[,c(32:43, 59:81)]))
head(z.data,2)
head(z.data[,c(32:43, 59:62, 66:75, 81)])
rcorr(as.matrix(z.data[,c(32:38,59:62, 66:75, 81)]))
rcorr(as.matrix(z.data[,c(59:62, 66:75, 81)]))
#####################################################################
#### Principal Component Regression for MBQ 2024 Boring Project #####
library(lme4)
library(tidyverse)
library(MASS)
raw.data.full <- read.csv("data/2024_boringData_masterSheet - complete_data(1).csv")
raw.data.no.diameters <- raw.data.full %>% dplyr::select(2:70)
#removes diameters, collector info, notes
raw.data.comb.dead <- raw.data.no.diameters %>% dplyr::mutate(not_alive_coral = dead_coral_total + turf_total + macroalgae_total + invertebrate_total)
raw.data <- raw.data.comb.dead %>% dplyr::select(-(44:54)) %>% na.omit
#####################################################################################################
###### Apply Principal Coordinate analysis to reduce dimensionality (i.e. reduce collinear variables)
pcr_input_predictors <- raw.data %>% dplyr::select(c(13:16,19, 28:32, 39, 40, 44:59))
pcr <- prcomp(pcr_input_predictors, center = TRUE, scale = TRUE)
pcr$rotation
pwd
get.wd()
getwd()
write.csv(pcr$rotation, "data/pca_loadings.csv")
pcr$x
#calculate total variance explained by each principal component
var_explained <- pcr$sdev^2 / sum(pcr$sdev^2)
var_explained
head(pcr)
head(pcr$x)
colnames(pcr$x)
var_per_pc <- cbind(var_explained, colnames(pcr$x))
var_per_pc
colnames(var_per_pc) <- c("var_explained", "PC")
write.csv(var_per_pc, "data/pca_variance_explained.csv")
##############################################
##### Negative Binomial GLMs #################
data_with_pca <- cbind(raw.data, pcr$x)
write.csv(data_with_pca, "data/boring_data_withPrincipalComponents.csv")
write.csv(pcr$rotation, "output/pca_loadings.csv")
write.csv(var_per_pc, "output/pca_variance_explained.csv")
write.csv(data_with_pca, "output/boring_data_withPrincipalComponents.csv")
head(pcr_input_predictors,1)
pca_L_onLive_nb
### L_onLive
pca_L_onLive_nb <-
zeroinfl(data = data_with_pca, dist = "negbin",
L_onLive ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12)
library(topmodels) # to check fit of models (must install from RForge)
### L_onLive
pca_L_onLive_nb <-
zeroinfl(data = data_with_pca, dist = "negbin",
L_onLive ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12)
#####################################################################
#### Principal Component Regression for MBQ 2024 Boring Project #####
library(lme4)
library(tidyverse)
library(MASS)
library(topmodels) # to check fit of models (must install from RForge)
raw.data.full <- read.csv("data/2024_boringData_masterSheet - complete_data(1).csv")
raw.data.no.diameters <- raw.data.full %>% dplyr::select(2:70)
#removes diameters, collector info, notes
raw.data.comb.dead <- raw.data.no.diameters %>% dplyr::mutate(not_alive_coral = dead_coral_total + turf_total + macroalgae_total + invertebrate_total)
raw.data <- raw.data.comb.dead %>% dplyr::select(-(44:54)) %>% na.omit
#####################################################################################################
###### Apply Principal Coordinate analysis to reduce dimensionality (i.e. reduce collinear variables)
pcr_input_predictors <- raw.data %>% dplyr::select(c(13:16,19, 28:32, 39, 40, 44:59))
pcr <- prcomp(pcr_input_predictors, center = TRUE, scale = TRUE)
pcr$rotation
pcr$x
#this is where the PCA results for each row are
biplot(pcr, scale = 0)
#calculate total variance explained by each principal component
var_explained <- pcr$sdev^2 / sum(pcr$sdev^2)
#PC1 explains 0.39 of the variance
#PC2 explains 0.13 of the variance
#PC3 explains 0.10
#PC4 explains 0.06
plot(var_explained)
var_per_pc <- cbind(var_explained, colnames(pcr$x))
colnames(var_per_pc) <- c("var_explained", "PC")
library(Hmisc)
rcorr(as.matrix(data_with_pca[,c("PC1", "PC2", "PC3", "PC4", "PC5", "PC6", "PC7", "PC8", "PC9", "L_onLive")]))
##############################################
##### Negative Binomial GLMs #################
data_with_pca <- cbind(raw.data, pcr$x)
### L_onLive
pca_L_onLive_nb <-
zeroinfl(data = data_with_pca, dist = "negbin",
L_onLive ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12)
require(topmodels)
### L_onDead
pca_L_onDead_nb <-
zeroinfl(data = data_with_pca, dist = "negbin",
L_onDead ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + PC13)
### L_onDead
pca_L_onDead_nb <-
topmodels::zeroinfl(data = data_with_pca, dist = "negbin",
L_onDead ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + PC13)
library(pscl)
### L_onLive
pca_L_onLive_nb <-
zeroinfl(data = data_with_pca, dist = "negbin",
L_onLive ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12)
pca_L_onLive_nb
# Remove PC13 to prevent 'system is computationally singular' warning
summary(pca_L_onLive_nb)
### L_onDead
pca_L_onDead_nb <-
zeroinfl(data = data_with_pca, dist = "negbin",
L_onDead ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + PC13)
summary(pca_L_onDead_nb)
### D_liveOnLive
pca_D_liveOnLive_nb <-
zeroinfl(data = data_with_pca, dist = "negbin",
D_liveOnLive ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11)
# Remove PC12 and PC13 to prevent 'system is computationally singular' warning
summary(pca_D_liveOnLive_nb)
### D_liveOnDead
pca_D_liveOnDead_nb <-
zeroinfl(data = data_with_pca, dist = "negbin",
D_liveOnDead ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + PC13)
summary(pca_D_liveOnDead_nb)
### D_deadOnLive
pca_D_deadOnLive_nb <-
zeroinfl(data = data_with_pca, dist = "negbin",
D_deadOnLive ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + PC13)
summary(pca_D_deadOnLive_nb)
### D_deadOnDead
pca_D_deadOnDead_nb <-
zeroinfl(data = data_with_pca, dist = "negbin",
D_deadOnDead ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + PC11 + PC12 + PC13)
summary(pca_D_deadOnDead_nb)
